mydata <- data %>%
mutate(logit = log(probabilities/(1-probabilities))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
library(dplyr)
predictors <- colnames(data)
mydata <- data %>%
+     mutate(logit = log(probabilities/(1-probabilities))) %>%
+     gather(key = "predictors", value = "predictor.value", -logit)
probabilities <- predict(best_model, type = "response")
predictors <- colnames(data)
mydata <- data %>%
+     mutate(logit = log(probabilities/(1-probabilities))) %>%
+     gather(key = "predictors", value = "predictor.value", -logit)
data
mydata
mydata <- data %>%
+     mutate(logit = log(probabilities/(1-probabilities))) %>%
+     gather(key = "predictors", value = "predictor.value", -logit)
mydata <- PimaIndiansDiabetes2 %>%
dplyr::select_if(is.numeric)
mydata <- data %>%
dplyr::select_if(is.numeric)
mydata
mydata == data
names(mydata)
names(data)
mydata <- data %>%
dplyr::select_if(is.numeric)
probabilities <- predict(best_model, type = "response")
predictors <- colnames(mydata)
mydata <- data %>%
+     mutate(logit = log(probabilities/(1-probabilities))) %>%
+     gather(key = "predictors", value = "predictor.value", -logit)
library(broom)
data("PimaIndiansDiabetes2", package = "mlbench")
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# Fit the logistic regression model
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,
family = binomial)
# Predict the probability (p) of diabete positivity
probabilities <- predict(model, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
head(predicted.classes)
mydata
PimaIndiansDiabetes2
data("PimaIndiansDiabetes2", package = "mlbench")
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# Fit the logistic regression model
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,
family = binomial)
# Predict the probability (p) of diabete positivity
probabilities <- predict(model, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
head(predicted.classes)
data("PimaIndiansDiabetes2", package = "mlbench")
library(mlbench)
data("PimaIndiansDiabetes2", package = "mlbench")
PimaIndiansDiabetes2 <- na.omit(PimaIndiansDiabetes2)
# Fit the logistic regression model
model <- glm(diabetes ~., data = PimaIndiansDiabetes2,
family = binomial)
# Predict the probability (p) of diabete positivity
probabilities <- predict(model, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, "pos", "neg")
head(predicted.classes)
PimaIndiansDiabetes2
mydata <- PimaIndiansDiabetes2 %>%
dplyr::select_if(is.numeric)
predictors <- colnames(mydata)
# Bind the logit and tidying the data for plot
mydata <- mydata %>%
mutate(logit = log(probabilities/(1-probabilities))) %>%
gather(key = "predictors", value = "predictor.value", -logit)
mydata <- mydata %>%
mutate(logit = log(probabilities/(1-probabilities)))
mydata
probabilities
mydata <- train.data %>%
dplyr::select_if(is.numeric)
probabilities <- predict(best_model, type = "response")
predictors <- colnames(mydata)
mydata <- data %>%
+     mutate(logit = log(probabilities/(1-probabilities))) %>%
+     gather(key = "predictors", value = "predictor.value", -logit)
probabilities
length(probabilities)
length(train.data)
# 8.A
set.seed(42)
data <- read.csv("Data.csv")
train.size <- floor(2/3 * nrow(data))
train.ind <- sample(seq_len(nrow(data)), size = train.size)
train.data <- data[train.ind, ]
test.data <- data[-train.ind, ]
full.model <- glm(Response ~ ., data = train.data, family = binomial)
summary(full.model)
nullmod <- glm(Response~1, data=data, family="binomial")
r2.adj <- function (null.model, model) {
1-logLik(model)/logLik(null.model)
}
vars <- c("Adhes", "BNucl", "Chrom", "Epith", "Mitos", "NNucl", "Thick", "UShap", "USize")
selected_vars <- c()
max_adj_r2 <- c(0)
while(T) {
rem_vars <- setdiff(vars, selected_vars)
# print(rem_vars)
if(length(rem_vars)==0) {
break
}
step_vars <- c()
for(j in length(rem_vars)) {
step_max_adj_r2 <- 0
current_var <- rem_vars[j]
# print(current_var)
step_vars <- c(selected_vars, current_var)
mod <- glm(as.formula(paste("Response",
paste(step_vars, collapse=" + "), sep=" ~ ")),
data=data,
family="binomial")
adjr2 <- r2.adj(nullmod, mod)
if(adjr2 > step_max_adj_r2) {
step_max_adj_r2 <- adjr2
step_best_model <- mod
step_best_var <- current_var
}
}
if(step_max_adj_r2 >= max_adj_r2[length(max_adj_r2)]) {
max_adj_r2 <- c(max_adj_r2, step_max_adj_r2)
best_model <- step_best_model
selected_vars <- c(selected_vars, step_best_var)
}
else {
print('here')
break
}
}
library(plotROC)
library(ggplot2)
train.data$pred=predict(best_model, newdata=train.data)
roc_curve_train <- ggplot(train.data,
aes(m = pred,
d = Response)) +
geom_roc(n.cuts=20,
labels=F) +
theme_classic()
show(roc_curve_train + annotate("text", x = .75, y = .25 , label =
paste("AUC For Train =",
round(calc_auc(roc_curve)["AUC"], 3))))
test.data$pred=predict(best_model, newdata=test.data)
roc_curve_test <- ggplot(test.data,
aes(m = pred,
d = Response)) +
geom_roc(n.cuts=20,
labels=F) +
theme_classic()
show(roc_curve_test + annotate("text", x = .75, y = .25 , label =
paste("AUC For Test =",
round(calc_auc(roc_curve)["AUC"], 3))))
library(mlbench)
library(dplyr)
mydata <- train.data %>%
dplyr::select_if(is.numeric)
probabilities <- predict(best_model, type = "response")
length(probabilities)
length(train.data)
length(data)
length(data)
# 8.A
set.seed(42)
data <- read.csv("Data.csv")
train.size <- floor(2/3 * nrow(data))
train.ind <- sample(seq_len(nrow(data)), size = train.size)
train.data <- data[train.ind, ]
test.data <- data[-train.ind, ]
full.model <- glm(Response ~ ., data = train.data, family = binomial)
summary(full.model)
nrow(train.data)
log(probabilities/(1-probabilities)
asd
log(probabilities/(1-probabilities))
length(log(probabilities/(1-probabilities)))
# 8.A
set.seed(42)
data <- read.csv("Data.csv")
train.size <- floor(2/3 * nrow(data))
train.ind <- sample(seq_len(nrow(data)), size = train.size)
train.data <- data[train.ind, ]
test.data <- data[-train.ind, ]
full.model <- glm(Response ~ ., data = train.data, family = binomial)
summary(full.model)
nullmod <- glm(Response~1, data=data, family="binomial")
r2.adj <- function (null.model, model) {
1-logLik(model)/logLik(null.model)
}
vars <- c("Adhes", "BNucl", "Chrom", "Epith", "Mitos", "NNucl", "Thick", "UShap", "USize")
selected_vars <- c()
max_adj_r2 <- c(0)
while(T) {
rem_vars <- setdiff(vars, selected_vars)
# print(rem_vars)
if(length(rem_vars)==0) {
break
}
step_vars <- c()
for(j in length(rem_vars)) {
step_max_adj_r2 <- 0
current_var <- rem_vars[j]
# print(current_var)
step_vars <- c(selected_vars, current_var)
mod <- glm(as.formula(paste("Response",
paste(step_vars, collapse=" + "), sep=" ~ ")),
data=train.data,
family="binomial")
adjr2 <- r2.adj(nullmod, mod)
if(adjr2 > step_max_adj_r2) {
step_max_adj_r2 <- adjr2
step_best_model <- mod
step_best_var <- current_var
}
}
if(step_max_adj_r2 >= max_adj_r2[length(max_adj_r2)]) {
max_adj_r2 <- c(max_adj_r2, step_max_adj_r2)
best_model <- step_best_model
selected_vars <- c(selected_vars, step_best_var)
}
else {
print('here')
break
}
}
library(plotROC)
library(ggplot2)
train.data$pred=predict(best_model, newdata=train.data)
roc_curve_train <- ggplot(train.data,
aes(m = pred,
d = Response)) +
geom_roc(n.cuts=20,
labels=F) +
theme_classic()
show(roc_curve_train + annotate("text", x = .75, y = .25 , label =
paste("AUC For Train =",
round(calc_auc(roc_curve)["AUC"], 3))))
test.data$pred=predict(best_model, newdata=test.data)
roc_curve_test <- ggplot(test.data,
aes(m = pred,
d = Response)) +
geom_roc(n.cuts=20,
labels=F) +
theme_classic()
show(roc_curve_test + annotate("text", x = .75, y = .25 , label =
paste("AUC For Test =",
round(calc_auc(roc_curve)["AUC"], 3))))
library(mlbench)
library(dplyr)
mydata <- train.data %>%
dplyr::select_if(is.numeric)
probabilities <- predict(best_model, type = "response")
predictors <- colnames(mydata)
mydata <- data %>%
+     mutate(logit = log(probabilities/(1-probabilities))) %>%
+     gather(key = "predictors", value = "predictor.value", -logit)
mydata <- train.data
probabilities <- predict(best_model, type = "response")
predictors <- colnames(mydata)
mydata <- data %>%
+     mutate(logit = log(probabilities/(1-probabilities))) %>%
+     gather(key = "predictors", value = "predictor.value", -logit)
mydata
train.data <- data[train.ind, ]
train.data
mydata <- data %>%
+     mutate(logit = log(probabilities/(1-probabilities))) %>%
+     gather(key = "predictors", value = "predictor.value", -logit)
mydata <- train.data
probabilities <- predict(best_model, type = "response")
predictors <- colnames(mydata)
mydata <- data %>%
+     mutate(logit = log(probabilities/(1-probabilities))) %>%
+     gather(key = "predictors", value = "predictor.value", -logit)
mydata
mydata <- train.data %>%
+     mutate(logit = log(probabilities/(1-probabilities))) %>%
+     gather(key = "predictors", value = "predictor.value", -logit)
library(dplyr)
mydata <- train.data
probabilities <- predict(best_model, type = "response")
predictors <- colnames(mydata)
mydata <- train.data %>%
+     mutate(logit = log(probabilities/(1-probabilities))) %>%
+     gather(key = "predictors", value = "predictor.value", -logit)
mydata <- train.data$logit = log(probabilities/(1-probabilities))
probabilities <- predict(best_model, type = "response")
predictors <- colnames(mydata)
train.data$logit <- = log(probabilities/(1-probabilities))
train.data$logit <- log(probabilities/(1-probabilities))
train.data$logit
train.data
train.data$logit <- log(probabilities/(1-probabilities)) %>%
gather(key = "predictors", value = "predictor.value", -logit)
train.data$logit <- log(probabilities/(1-probabilities)) %>%
gather(key = "predictors", value = "predictor.value", -logit)
gather
train.data$logit <- log(probabilities/(1-probabilities)) %>%
gather(key = "predictors", value = "predictor.value", -logit)
library(tidyverse)
library(tidyverse)
probabilities <- predict(best_model, type = "response")
predictors <- colnames(mydata)
train.data$logit <- log(probabilities/(1-probabilities)) %>%
gather(key = "predictors", value = "predictor.value", -logit)
class(train.data$logit)
class(log(probabilities/(1-probabilities))))
class(log(probabilities/(1-probabilities)))
gather(train.data, key = "predictors", value = "predictor.value", -logit)
pairs <- gather(train.data, key = "predictors", value = "predictor.value", -logit)
ggplot(pairs, aes(logit, predictor.value))+
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_y")
max_adj_r2
train.data$logit <- log(probabilities/(1-probabilities))
pairs <- gather(train.data, key = "predictors", value = "predictor.value", -logit)
#8.D
library(dplyr)
library(tidyverse)
probabilities <- predict(best_model, type = "response")
predictors <- colnames(mydata)
train.data$logit <- log(probabilities/(1-probabilities))
pairs <- gather(train.data, key = "predictors", value = "predictor.value", -logit)
ggplot(pairs, aes(logit, predictor.value))+
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_y")
train.data$pred=predict(best_model, newdata=train.data)
roc_curve_train <- ggplot(train.data,
aes(m = pred,
d = Response)) +
geom_roc(n.cuts=20,
labels=F) +
theme_classic()
show(roc_curve_train + annotate("text", x = .75, y = .25 , label =
paste("AUC For Train =",
round(calc_auc(roc_curve)["AUC"], 3))))
show(roc_curve_train + annotate("text", x = .75, y = .25 , label =
paste("AUC For Train =",
round(calc_auc(roc_curve_train)["AUC"], 3))))
test.data$pred=predict(best_model, newdata=test.data)
roc_curve_test <- ggplot(test.data,
aes(m = pred,
d = Response)) +
geom_roc(n.cuts=20,
labels=F) +
theme_classic()
show(roc_curve_test + annotate("text", x = .75, y = .25 , label =
paste("AUC For Test =",
round(calc_auc(roc_curve)["AUC"], 3))))
roc_curve_train <- ggplot(train.data,
aes(m = pred,
d = Response)) +
geom_roc(n.cuts=20,
labels=F) +
theme_classic()
show(roc_curve_train + annotate("text", x = .75, y = .25 , label =
paste("AUC For Train =",
round(calc_auc(roc_curve_train)["AUC"], 3))))
test.data$pred=predict(best_model, newdata=test.data)
roc_curve_test <- ggplot(test.data,
aes(m = pred,
d = Response)) +
geom_roc(n.cuts=20,
labels=F) +
theme_classic()
show(roc_curve_test + annotate("text", x = .75, y = .25 , label =
paste("AUC For Test =",
round(calc_auc(roc_curve)["AUC"], 3))))
show(roc_curve_test + annotate("text", x = .75, y = .25 , label =
paste("AUC For Test =",
round(calc_auc(roc_curve_test)["AUC"], 3))))
library(tidyverse)
probabilities <- predict(best_model, type = "response")
predictors <- colnames(mydata)
train.data$logit <- log(probabilities/(1-probabilities))
pairs <- gather(train.data, key = "predictors", value = "predictor.value", -logit)
ggplot(pairs, aes(logit, predictor.value))+
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_y")
(800-85)/800
x=(800-85)/800
(0.867*0.02) / (x*0.98 + 0.867*0.02)
x*0.98
(0.867*0.02) / ((1-x)*0.98 + 0.867*0.02)
nullmod <- glm(Response~1, data=data, family="binomial")
r2.adj <- function (null.model, model) {
1-logLik(model)/logLik(null.model)
}
vars <- c("Adhes", "BNucl", "Chrom", "Epith", "Mitos", "NNucl", "Thick", "UShap", "USize")
selected_vars <- c()
max_adj_r2 <- c(0)
while(T) {
rem_vars <- setdiff(vars, selected_vars)
# print(rem_vars)
if(length(rem_vars)==0) {
break
}
step_vars <- c()
for(j in length(rem_vars)) {
step_max_adj_r2 <- 0
current_var <- rem_vars[j]
# print(current_var)
step_vars <- c(selected_vars, current_var)
mod <- glm(as.formula(paste("Response",
paste(step_vars, collapse=" + "), sep=" ~ ")),
data=train.data,
family="binomial")
adjr2 <- r2.adj(nullmod, mod)
if(adjr2 > step_max_adj_r2) {
step_max_adj_r2 <- adjr2
step_best_model <- mod
step_best_var <- current_var
}
}
if(step_max_adj_r2 >= max_adj_r2[length(max_adj_r2)]) {
max_adj_r2 <- c(max_adj_r2, step_max_adj_r2)
best_model <- step_best_model
selected_vars <- c(selected_vars, step_best_var)
}
else {
print('here')
break
}
}
library(plotROC)
library(plotROC)
library(ggplot2)
#8.D
library(dplyr)
library(tidyverse)
probabilities <- predict(best_model, type = "response")
predictors <- colnames(mydata)
train.data$logit <- log(probabilities/(1-probabilities))
pairs <- gather(train.data, key = "predictors", value = "predictor.value", -logit)
ggplot(pairs, aes(logit, predictor.value))+
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_y")
library(plotROC)
library(ggplot2)
train.data$pred=predict(best_model, newdata=train.data)
roc_curve_train <- ggplot(train.data,
aes(m = pred,
d = Response)) +
geom_roc(n.cuts=20,
labels=F) +
theme_classic()
show(roc_curve_train + annotate("text", x = .75, y = .25 , label =
paste("AUC For Train =",
round(calc_auc(roc_curve_train)["AUC"], 3))))
test.data$pred=predict(best_model, newdata=test.data)
roc_curve_test <- ggplot(test.data,
aes(m = pred,
d = Response)) +
geom_roc(n.cuts=20,
labels=F) +
theme_classic()
show(roc_curve_test + annotate("text", x = .75, y = .25 , label =
paste("AUC For Test =",
round(calc_auc(roc_curve_test)["AUC"], 3))))
#8.E
library(dplyr)
library(tidyverse)
probabilities <- predict(best_model, type = "response")
predictors <- colnames(mydata)
train.data$logit <- log(probabilities/(1-probabilities))
pairs <- gather(train.data, key = "predictors", value = "predictor.value", -logit)
ggplot(pairs, aes(logit, predictor.value))+
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_y")
pairs <- gather(train.data[:, -c(pred, Response)], key = "predictors", value = "predictor.value", -logit)
pairs <- gather(train.data[, -c(pred, Response)], key = "predictors", value = "predictor.value", -logit)
pairs <- gather(train.data[, -c("pred", "Response")], key = "predictors", value = "predictor.value", -logit)
pairs <- gather(train.data[, !(names(train.data) in c("pred", "Response"))], key = "predictors", value = "predictor.value", -logit)
pairs <- gather(train.data[, !(names(train.data) %in% c("pred", "Response"))], key = "predictors", value = "predictor.value", -logit)
ggplot(pairs, aes(logit, predictor.value))+
geom_point(size = 0.5, alpha = 0.5) +
geom_smooth(method = "loess") +
theme_bw() +
facet_wrap(~predictors, scales = "free_y")
plot(max_adj_r2)
print("selected variables are:",)
print(selected_vars)
plot(max_adj_r2[2:])
print("selected variables are:",)
plot(max_adj_r2[2,3,4])
max_adj_r2[seq(1,4)]
plot(max_adj_r2[seq(2, length(max_adj_r2))])
max_adj_r2[seq(1,4)]seq(2, length(max_adj_r2))
seq(2, length(max_adj_r2))
plot(max_adj_r2[seq(2, length(max_adj_r2))])
plot(max_adj_r2[seq(2, length(max_adj_r2))],
main = "adjusted R squared",
xlab = "step",
ylab = "adj. R^2")
print("selected variables are:",)
print("selected variables are:",)
print(selected_vars)
